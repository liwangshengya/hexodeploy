---
title: 第三章卷积介绍
date: 2022-02-22 17:46:15
tags:
    - tensorflow
categories: tensorflow
copyright: false
---

注：该分类下的文章教程部分均来自MOOC的([TensorFlow 入门实操课程_网易有道_中国大学MOOC(慕课) (icourse163.org)](https://www.icourse163.org/course/youdao-1460578162)),文章最后的练习部分是自己写的

## 利用卷积提高计算机视觉精度

在前几节课中，你看到了如何使用包含三层的深度神经网络（DNN）进行时Fashion MNIST图像识别--输入层（根据输入数据的形状）、输出层（根据类别数量）和一个隐藏层。你实验了不同大小的隐藏层、训练次数等对最终精度的影响。

为了方便起见，这里又提供了完整的代码。运行它，记下最后打印出来的测试精度。


```python
import tensorflow as tf
mnist = tf.keras.datasets.fashion_mnist
(training_images, training_labels), (test_images, test_labels) = mnist.load_data()
training_images=training_images / 255.0
test_images=test_images / 255.0
model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(128, activation=tf.nn.relu),
  tf.keras.layers.Dense(10, activation=tf.nn.softmax)
])
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.fit(training_images, training_labels, epochs=5)

test_loss = model.evaluate(test_images, test_labels)
```

    Epoch 1/5
    1875/1875 [==============================] - 2s 1ms/step - loss: 0.4969 - accuracy: 0.8265
    Epoch 2/5
    1875/1875 [==============================] - 2s 1ms/step - loss: 0.3727 - accuracy: 0.8669
    Epoch 3/5
    1875/1875 [==============================] - 2s 1ms/step - loss: 0.3372 - accuracy: 0.8781
    Epoch 4/5
    1875/1875 [==============================] - 2s 1ms/step - loss: 0.3131 - accuracy: 0.8859
    Epoch 5/5
    1875/1875 [==============================] - 2s 1ms/step - loss: 0.2955 - accuracy: 0.8921
    313/313 [==============================] - 0s 897us/step - loss: 0.3591 - accuracy: 0.8744

你的训练准确率大概是89%，测试准确率大概是87%......还不错......但是如何让它变得更好呢？一种方法是使用一种叫做Convolutions的方法。这里不打算纠结于卷积的细节，而想抓住它的核心思路，即通过卷积操作缩小了图像的内容，将模型注意力集中在图像特定的、明显的特征上。

如果你曾经使用滤镜进行过图像处理（比如：https://en.wikipedia.org/wiki/Kernel_(image_processing)），那么convolutions看起来会非常熟悉。

简而言之，如果取一个二维数组（通常是3x3或5x5）并将其应用到图像上。通过根据该矩阵内的公式改变底层像素，就可以进行图像边缘检测等工作。例如上面的链接，会看到一个3x3的矩阵，它是为边缘检测而定义的，其中间的单元格是8，而所有相邻单元格都是-1。在这种情况下，对于每个像素，把它的值乘以8，然后减去它周边像素的值（因为每个都乘了-1）。扫描整个图像，对每个像素都这样做，最终会得到一张边缘被增强的新图像。

这种计算对于计算机视觉来说是非常理想的，因为通常情况下，能够像这样被突出显示的特征才是区分一个物品和另一个物品的关键。卷积使得所需要的信息量会少很多......因为只需要对突出显示的特征进行训练。

这就是卷积神经网络的概念。在全连接层之前，增加一些层来做卷积，那么输入全连接层的信息就会更加集中，也可能更加准确。

运行下面的代码--这和前面的神经网络是一样的，但这次先加了卷积层。这会花费较长的时间，但看看对精度的影响。



```python
import tensorflow as tf
print(tf.__version__)
mnist = tf.keras.datasets.fashion_mnist
(training_images, training_labels), (test_images, test_labels) = mnist.load_data()
training_images=training_images.reshape(60000, 28, 28, 1)
training_images=training_images / 255.0
test_images = test_images.reshape(10000, 28, 28, 1)
test_images=test_images/255.0
model = tf.keras.models.Sequential([
  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),
  tf.keras.layers.MaxPooling2D(2, 2),
  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
  tf.keras.layers.MaxPooling2D(2,2),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dense(10, activation='softmax')
])
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.summary()
model.fit(training_images, training_labels, epochs=5)
test_loss = model.evaluate(test_images, test_labels)

```

    2.2.0
    Model: "sequential_1"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d (Conv2D)              (None, 26, 26, 64)        640       
    _________________________________________________________________
    max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         
    _________________________________________________________________
    conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     
    _________________________________________________________________
    max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         
    _________________________________________________________________
    flatten_1 (Flatten)          (None, 1600)              0         
    _________________________________________________________________
    dense_2 (Dense)              (None, 128)               204928    
    _________________________________________________________________
    dense_3 (Dense)              (None, 10)                1290      
    =================================================================
    Total params: 243,786
    Trainable params: 243,786
    Non-trainable params: 0
    _________________________________________________________________
    Epoch 1/5
    1875/1875 [==============================] - 35s 19ms/step - loss: 0.4311 - accuracy: 0.8443
    Epoch 2/5
    1875/1875 [==============================] - 35s 19ms/step - loss: 0.2897 - accuracy: 0.8949
    Epoch 3/5
    1875/1875 [==============================] - 35s 19ms/step - loss: 0.2473 - accuracy: 0.9079
    Epoch 4/5
    1875/1875 [==============================] - 35s 19ms/step - loss: 0.2162 - accuracy: 0.9205
    Epoch 5/5
    1875/1875 [==============================] - 35s 19ms/step - loss: 0.1914 - accuracy: 0.9292
    313/313 [==============================] - 2s 5ms/step - loss: 0.2541 - accuracy: 0.9108

模型在训练数据上的精度可能上升到93%左右，在验证数据上可能上升到91%。

这是朝着正确方向取得的显著进步!

试着运行更多的epochs--比如20个epochs，然后观察结果! 虽然结果可能看起来非常好，但实际上验证结果可能会下降，这是因为"过拟合"造成的，后面将会讨论。

(简而言之，'过拟合'发生在网络模型从训练集中学习到的结果非常好，但它太狭隘了，只能识别训练数据，而在看到*其他*数据时效果不佳。举个例子，如果你一辈子只看到红色的鞋子，那么当你看到一双蓝色的麂皮鞋可能会感到迷惑......再举一例，应试教育往往使得学生只对做过的题目有很好的正确率，但对真实的问题却错误率很高）

接下来，观察程序代码，看看卷积模型是如何一步步建立的。

第一步是收集数据。你会注意到，这里和之前有一点变化，训练数据需要改变维度（shape）。这是因为第一次卷积期望一个包含所有数据的单一张量，所以要把训练数据设置为60000x28x28x1的一个4D列表，测试图像也是如此处理。如果不这样做，会在训练时得到一个错误，因为卷积操作将不能识别数据形状。

```
import tensorflow as tf
mnist = tf.keras.datasets.fashion_mnist
(training_images, training_labels), (test_images, test_labels) = mnist.load_data()
training_images=training_images.reshape(60000, 28, 28, 1)
training_images=training_images / 255.0
test_images = test_images.reshape(10000, 28, 28, 1)
test_images=test_images/255.0
```

接下来是定义模型。首先要添加一个卷积层。参数是

1. 你想要生成的卷积数（过滤器数量）。这个数值是任意的，但最好是从32开始的倍数。
2. 卷积的大小（过滤器的大小），在本例中为3x3网格。这是最常用的尺寸。
3. 要使用的激活函数 -- 在本例中，我们将使用relu，你可能还记得它相当于当x>0时返回x，否则返回0。
4. 在第一层，设定输入数据的形状。

在卷积层之后加上一个MaxPooling层，用来压缩图像，同时保持卷积所强调的特征内容。通过为MaxPooling指定(2,2)，效果是将图像的大小缩小四分之一。它的想法是创建一个2x2的像素数组，然后选取最大的一个，从而将4个像素变成1个，在整个图像中重复这样做，这样做的结果是将水平像素的数量减半，垂直像素的数量减半，有效地将图像缩小25%。

可以调用model.summary()来查看网络的大小和形状，你会注意到，每一个MaxPooling（池化）层之后，图像的大小都会以这种方式减少为原来的1/4。

```
model = tf.keras.models.Sequential([
  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),
  tf.keras.layers.MaxPooling2D(2, 2),
```

再增加一个卷积层和MaxPooling2D


```
  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
  tf.keras.layers.MaxPooling2D(2,2)
```

现在对输出进行扁平化处理。在这之后，你将拥有与非卷积版本相同的DNN结构，即全连接神经元网络。

```
  tf.keras.layers.Flatten(),
```



含有128个神经元的全连接层，以及10个神经元的输出层。

```
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dense(10, activation='softmax')
])
```

现在编译模型，调用model.fit方法做训练，接着用测试集评估损失和准确率。

```
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.fit(training_images, training_labels, epochs=5)
test_loss, test_acc = model.evaluate(test_images, test_labels)
print(test_acc)
```

## 将卷积和池化的结果可视化

这段代码将以图形方式向我们展示卷积的结果。print(test_labels[;100])向我们展示了测试集中的前100个标签，你可以看到索引0、索引23和索引28的标签都是相同的值（9），它们都是鞋子。让我们来看看对图像做卷积操作的结果，会看到它们之间的共同特征出现。之后，当DNN在该数据上进行训练时，模型训练的工作内容就少了很多，模型会在卷积/池化的基础上找到鞋子图像的共性。


```python
print(test_labels[:100])
```

    [9 2 1 1 6 1 4 6 5 7 4 5 7 3 4 1 2 4 8 0 2 5 7 9 1 4 6 0 9 3 8 8 3 3 8 0 7
     5 7 9 6 1 3 7 6 7 2 1 2 2 4 4 5 8 2 2 8 4 8 0 7 7 8 5 1 1 2 3 9 8 7 0 2 6
     2 3 1 2 8 4 1 8 5 9 5 0 3 2 0 6 5 3 6 7 1 8 0 1 4 2]



```python
import matplotlib.pyplot as plt
f, axarr = plt.subplots(3,4)
FIRST_IMAGE=0
SECOND_IMAGE=7
THIRD_IMAGE=26
CONVOLUTION_NUMBER = 1
from tensorflow.keras import models
layer_outputs = [layer.output for layer in model.layers]
activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)
for x in range(0,4):
  f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]
  axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')
  axarr[0,x].grid(False)
  f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]
  axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')
  axarr[1,x].grid(False)
  f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]
  axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')
  axarr[2,x].grid(False)
```


​    
![png](https://cdn.jsdelivr.net/gh/liwangshengya/picture/img/202202221726367.png)
​    



```python
import tensorflow as tf
from tensorflow import keras
print(tf.__version__)
mnist = tf.keras.datasets.fashion_mnist
(training_images, training_labels), (test_images, test_labels) = mnist.load_data()
training_images=training_images.reshape(60000, 28, 28, 1)
training_images=training_images / 255.0
test_images = test_images.reshape(10000, 28, 28, 1)
test_images=test_images/255.0
network=keras.models.Sequential()
network.add(keras.layers.Conv2D(64,(2,2),activation=tf.nn.relu,input_shape=(28,28,1)))
network.add(keras.layers.MaxPooling2D(2,2))
network.add(keras.layers.Conv2D(128,(2,2),activation=tf.nn.relu))
network.add(keras.layers.MaxPooling2D(2,2))

network.add(keras.layers.Flatten())
network.add(keras.layers.Dense(200,activation=tf.nn.relu))
network.add(keras.layers.Dense(10,activation=tf.nn.softmax))
network.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
network.fit(training_images,training_labels,epochs=5)
```

    2.7.0


    2022-02-22 16:53:49.790908: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
    To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
    2022-02-22 16:53:50.300507: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 188160000 exceeds 10% of free system memory.


    Epoch 1/5
    1875/1875 [==============================] - 157s 83ms/step - loss: 0.4046 - accuracy: 0.8540
    Epoch 2/5
    1875/1875 [==============================] - 157s 84ms/step - loss: 0.2700 - accuracy: 0.8993
    Epoch 3/5
    1875/1875 [==============================] - 166s 89ms/step - loss: 0.2233 - accuracy: 0.9165
    Epoch 4/5
    1875/1875 [==============================] - 157s 84ms/step - loss: 0.1858 - accuracy: 0.9296
    Epoch 5/5
    1875/1875 [==============================] - 170s 91ms/step - loss: 0.1553 - accuracy: 0.9415





    <keras.callbacks.History at 0x7f4149a35fa0>




```python
import matplotlib.pyplot as plt
layer_outputs=[layer.output for layer in network.layers]
activation_model=tf.keras.models.Model(inputs=network.input,outputs=layer_outputs)
pred=activation_model.predict(test_images[0].reshape(1,28,28,1))
```


```python
len(pred)#7层的输出
```




    7




```python
plt.imshow(test_images[0])
```


```python
plt.imshow(pred[1][0,:,:,1])#第一层卷积第二个过滤器
```




    <matplotlib.image.AxesImage at 0x7f412e7f8610>




![png](https://cdn.jsdelivr.net/gh/liwangshengya/picture/img/202202221726970.png)
    



```python
f,axarr=plt.subplots(4)
for i in range(0,4):
    axarr[i].imshow(pred[i][0,:,:,1])
```


![png](https://cdn.jsdelivr.net/gh/liwangshengya/picture/img/202202221726694.png)

练习

1. 尝试修改卷积层参数。将32改为16或64。这对准确度和/或训练时间有什么影响？

2. 删除最后的卷积层。这将对精度或训练时间产生什么影响？

3. 增加更多的卷积层会有什么影响？实验一下吧。

4. 除第一项外，删除所有的Convolutions。这样做会有什么影响？请完成实验。

5. 在上一节课中，实现了通过一个回调函数来检查模型的损失，并在损失减小到一定量时取消训练。看看是否能在这里实现？


```python
import tensorflow as tf
print(tf.__version__)
mnist = tf.keras.datasets.mnist
(training_images, training_labels), (test_images, test_labels) = mnist.load_data()
training_images=training_images.reshape(60000, 28, 28, 1)
training_images=training_images / 255.0
test_images = test_images.reshape(10000, 28, 28, 1)
test_images=test_images/255.0
model = tf.keras.models.Sequential([
  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),
  tf.keras.layers.MaxPooling2D(2, 2),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dense(10, activation='softmax')
])
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.fit(training_images, training_labels, epochs=10)
test_loss, test_acc = model.evaluate(test_images, test_labels)
print(test_acc)
```

    2.2.0
    Epoch 1/10
    1875/1875 [==============================] - 17s 9ms/step - loss: 0.1538 - accuracy: 0.9537
    Epoch 2/10
    1875/1875 [==============================] - 17s 9ms/step - loss: 0.0519 - accuracy: 0.9843
    Epoch 3/10
    1875/1875 [==============================] - 16s 9ms/step - loss: 0.0345 - accuracy: 0.9890
    Epoch 4/10
    1875/1875 [==============================] - 17s 9ms/step - loss: 0.0226 - accuracy: 0.9934
    Epoch 5/10
    1875/1875 [==============================] - 17s 9ms/step - loss: 0.0154 - accuracy: 0.9955
    Epoch 6/10
    1875/1875 [==============================] - 17s 9ms/step - loss: 0.0105 - accuracy: 0.9965
    Epoch 7/10
    1875/1875 [==============================] - 17s 9ms/step - loss: 0.0086 - accuracy: 0.9972
    Epoch 8/10
    1875/1875 [==============================] - 16s 9ms/step - loss: 0.0065 - accuracy: 0.9978
    Epoch 9/10
    1875/1875 [==============================] - 17s 9ms/step - loss: 0.0057 - accuracy: 0.9981
    Epoch 10/10
    1875/1875 [==============================] - 17s 9ms/step - loss: 0.0039 - accuracy: 0.9987
    313/313 [==============================] - 1s 3ms/step - loss: 0.0580 - accuracy: 0.9866
    0.9865999817848206

##  卷积的程序实现

这里，通过一张二维灰度图像，来探索卷积的工作原理。可以从scipy库中获取名为"上升"的图像。这是一张漂亮的内置图片，有很多角度和线条。


```python
import cv2
import numpy as np
from scipy import misc
i = misc.ascent()

```

接下来，可以使用pyplot库来绘制图像，这样我们就能看到它的样子了。


```python
import matplotlib.pyplot as plt
plt.grid(False)
plt.gray()
plt.axis('off')
plt.imshow(i)
plt.show()
```


![png](https://cdn.jsdelivr.net/gh/liwangshengya/picture/img/202202221728554.png)


图像是以numpy数组的形式存储的，所以我们只需复制这个数组就可以对图像进行转换。我们还可以得到图像的尺寸，这样就可以用循环遍历它的数据。


```python
i_transformed = np.copy(i)
size_x = i_transformed.shape[0]
size_y = i_transformed.shape[1]
i_transformed.shape
```




    (512, 512)

接下来创建一个3x3的过滤器


```python
# This filter detects edges nicely
# It creates a convolution that only passes through sharp edges and straight
# lines.
# 这个过滤器可以很好地检测到边缘。
# 它通过卷积运算，只让尖锐的边缘和直线通过。

#Experiment with different values for fun effects.
#试试看修改过滤器的数值，玩玩看
#filter = [ [0, 1, 0], [1, -4, 1], [0, 1, 0]]

# A couple more filters to try for fun!
# 另外的几个过滤器，纯粹为了好玩！
filter = [ [-1, -2, -1], [0, 0, 0], [1, 2, 1]]
#filter = [ [-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]

# If all the digits in the filter don't add up to 0 or 1, you 
# should probably do a weight to get it to do so
# so, for example, if your weights are 1,1,1 1,2,1 1,1,1
# They add up to 10, so you would set a weight of .1 if you want to normalize them
# 如果过滤器中的所有数字加起来不是0或1，那么就应该设置权重，让过滤器的总和为0或1。
# 例如，如果过滤器是1，1，1，1，2，1，1，1，1。
# 它们加起来是10，所以可以设置0.1的权重，使它标准化。
weight  = 1
```

接下来让我们创建一个卷积，扫描整个图像，留出1个像素的边框，并将当前像素的每个邻居乘以过滤器中定义的值。

即当前像素上方和左侧的邻域将乘以滤镜中左上方的项，等等。然后我们再将结果乘以权重，然后确保结果在0-255的范围内。

最后我们将把新的值加载到转换后的图像中。


```python
for x in range(1,size_x-1):
  for y in range(1,size_y-1):
      convolution = 0.0
      convolution = convolution + (i[x - 1, y-1] * filter[0][0])
      convolution = convolution + (i[x, y-1] * filter[0][1])
      convolution = convolution + (i[x + 1, y-1] * filter[0][2])
      convolution = convolution + (i[x-1, y] * filter[1][0])
      convolution = convolution + (i[x, y] * filter[1][1])
      convolution = convolution + (i[x+1, y] * filter[1][2])
      convolution = convolution + (i[x-1, y+1] * filter[2][0])
      convolution = convolution + (i[x, y+1] * filter[2][1])
      convolution = convolution + (i[x+1, y+1] * filter[2][2])
      convolution = convolution * weight
      if(convolution<0):
        convolution=0
      if(convolution>255):
        convolution=255
      i_transformed[x, y] = convolution
```

现在，我们可以绘制图像，看看卷积的效果!


```python
# Plot the image. Note the size of the axes -- they are 512 by 512
plt.gray()
plt.grid(False)
plt.imshow(i_transformed)
#plt.axis('off')
plt.show()   
```


![png](https://cdn.jsdelivr.net/gh/liwangshengya/picture/img/202202221729839.png)

这段代码将显示一个（2，2）池化后的效果。它的想法是用2x2尺寸的矩阵在图像上扫描，查看像素和它的右方、下方和右下方的近邻像素。取其中最大的一个，并将其加载到新图像中。这样，新的图像将是旧图像的1/4大小--通过这个过程，X和Y上的尺寸减半。你会发现，尽管进行了这样的压缩，图像特征还是得到了保留。


```python
new_x = int(size_x/2)
new_y = int(size_y/2)
newImage = np.zeros((new_x, new_y))
for x in range(0, size_x, 2):
  for y in range(0, size_y, 2):
    pixels = []
    pixels.append(i_transformed[x, y])
    pixels.append(i_transformed[x+1, y])
    pixels.append(i_transformed[x, y+1])
    pixels.append(i_transformed[x+1, y+1])
    newImage[int(x/2),int(y/2)] = max(pixels)

# Plot the image. Note the size of the axes -- now 256 pixels instead of 512
plt.gray()
plt.grid(False)
plt.imshow(newImage)
#plt.axis('off')
plt.show()      
    
    
```


![png](https://cdn.jsdelivr.net/gh/liwangshengya/picture/img/202202221729799.png)
    

## 练习

在视频中，你看了如何使用卷积来提高Fashion MNIST的识别率。通过这个练习，看看可否只使用单个卷积层和单个MaxPooling 2D将MNIST（手写数字）识别率提高到99.8%或更高的准确率。一旦准确率超过这个数值，应该停止训练。Epochs不应超过20个。如果epochs达到20但精度未达到要求，那么就需要重新设计层结构。

程序的框架已经有了--请完成它!

当达到99.8%的准确率时，你应该打印出 "达到99.8%准确率，所以取消训练！"的字符串。


```python
import tensorflow as tf

# YOUR CODE STARTS HERE

# YOUR CODE ENDS HERE

mnist = tf.keras.datasets.mnist
(training_images, training_labels), (test_images, test_labels) = mnist.load_data()

# YOUR CODE STARTS HERE

# YOUR CODE ENDS HERE

model = tf.keras.models.Sequential([
    # YOUR CODE STARTS HERE

    # YOUR CODE ENDS HERE
])

# YOUR CODE STARTS HERE

# YOUR CODE ENDS HERE


```


```python
import tensorflow as tf
from tensorflow import keras
```


```python
class mycallbacks(tf.keras.callbacks.Callback):
#     def on_epoch_end(self,epoch,logs={}):
#         if(log)
    def on_epoch_end(self, epoch, logs={}):
        if(logs.get('accuracy')>0.999):
          print("\nReached 99.9% accuracy so cancelling training!")
          self.model.stop_training = True
callbacks=mycallbacks()
```


```python
mnist=keras.datasets.mnist
(training_images, training_labels), (test_images, test_labels) = mnist.load_data()
```


```python
print(training_images.shape)
print(training_labels.shape)
```

    (60000, 28, 28)
    (60000,)



```python
training_images=training_images.reshape(-1,28,28,1)/255.0
test_images=test_images.reshape(-1,28,28,1)/255.0
```


```python
network=keras.models.Sequential()
network.add(keras.layers.Conv2D(64,(2,2),activation=tf.nn.relu,input_shape=(28,28,1)))
network.add(keras.layers.MaxPooling2D(2,2))
# network.add(keras.layers.Conv2D(128,(2,2),activation=tf.nn.relu))
# network.add(keras.layers.MaxPooling2D(2,2))

network.add(keras.layers.Flatten())
network.add(keras.layers.Dense(200,activation=tf.nn.relu))
network.add(keras.layers.Dense(10,activation=tf.nn.softmax))
```

    2022-02-22 16:06:27.047181: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
    To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.



```python
network.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
network.fit(training_images,training_labels,epochs=20,callbacks=callbacks)
```

    2022-02-22 16:06:31.168558: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 188160000 exceeds 10% of free system memory.


```python
Epoch 1/20
1875/1875 [==============================] - 150s 79ms/step - loss: 0.1490 - accuracy: 0.9558
Epoch 2/20
1875/1875 [==============================] - 157s 84ms/step - loss: 0.0534 - accuracy: 0.9834
Epoch 3/20
1875/1875 [==============================] - 149s 79ms/step - loss: 0.0323 - accuracy: 0.9898
Epoch 4/20
1875/1875 [==============================] - 152s 81ms/step - loss: 0.0212 - accuracy: 0.9933
Epoch 5/20
1875/1875 [==============================] - 150s 80ms/step - loss: 0.0141 - accuracy: 0.9955
Epoch 6/20
1875/1875 [==============================] - 151s 81ms/step - loss: 0.0097 - accuracy: 0.9969
Epoch 7/20
1875/1875 [==============================] - 150s 80ms/step - loss: 0.0088 - accuracy: 0.9972
Epoch 8/20
1875/1875 [==============================] - 148s 79ms/step - loss: 0.0072 - accuracy: 0.9974
Epoch 9/20
1875/1875 [==============================] - 149s 79ms/step - loss: 0.0055 - accuracy: 0.9982
Epoch 10/20
1875/1875 [==============================] - 153s 82ms/step - loss: 0.0046 - accuracy: 0.9985
Epoch 11/20
1875/1875 [==============================] - 147s 78ms/step - loss: 0.0053 - accuracy: 0.9983
Epoch 12/20
1875/1875 [==============================] - 145s 77ms/step - loss: 0.0032 - accuracy: 0.9988
Epoch 13/20
1875/1875 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991
Reached 99.9% accuracy so cancelling training!
1875/1875 [==============================] - 147s 78ms/step - loss: 0.0028 - accuracy: 0.9991
```


```python
network.evaluate(test_images,test_labels)
```

    2022-02-22 16:48:20.830716: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 31360000 exceeds 10% of free system memory.


    313/313 [==============================] - 6s 18ms/step - loss: 0.0745 - accuracy: 0.9861
    
    [0.07454605400562286, 0.9861000180244446]
