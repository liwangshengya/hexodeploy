<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>第三章卷积介绍 | Hexo</title><meta name="keywords" content="tensorflow"><meta name="author" content="忘生啊"><meta name="copyright" content="忘生啊"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="注：该分类下的文章教程部分均来自MOOC的(TensorFlow 入门实操课程_网易有道_中国大学MOOC(慕课) (icourse163.org)),文章最后的练习部分是自己写的 利用卷积提高计算机视觉精度 在前几节课中，你看到了如何使用包含三层的深度神经网络（DNN）进行时Fashion MNIST图像识别–输入层（根据输入数据的形状）、输出层（根据类别数量）和一个隐藏层。你实验了不同大小的隐">
<meta property="og:type" content="article">
<meta property="og:title" content="第三章卷积介绍">
<meta property="og:url" content="https://hexo.chunyang.eu.org/2022/02/22/%E7%AC%AC%E4%B8%89%E7%AB%A0%E5%8D%B7%E7%A7%AF%E4%BB%8B%E7%BB%8D/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="注：该分类下的文章教程部分均来自MOOC的(TensorFlow 入门实操课程_网易有道_中国大学MOOC(慕课) (icourse163.org)),文章最后的练习部分是自己写的 利用卷积提高计算机视觉精度 在前几节课中，你看到了如何使用包含三层的深度神经网络（DNN）进行时Fashion MNIST图像识别–输入层（根据输入数据的形状）、输出层（根据类别数量）和一个隐藏层。你实验了不同大小的隐">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg">
<meta property="article:published_time" content="2022-02-22T09:46:15.000Z">
<meta property="article:modified_time" content="2022-02-22T09:58:02.773Z">
<meta property="article:author" content="忘生啊">
<meta property="article:tag" content="tensorflow">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://hexo.chunyang.eu.org/2022/02/22/%E7%AC%AC%E4%B8%89%E7%AB%A0%E5%8D%B7%E7%A7%AF%E4%BB%8B%E7%BB%8D/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '第三章卷积介绍',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-02-22 17:58:02'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.0.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">23</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">39</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Hexo</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">第三章卷积介绍</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-02-22T09:46:15.000Z" title="发表于 2022-02-22 17:46:15">2022-02-22</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-02-22T09:58:02.773Z" title="更新于 2022-02-22 17:58:02">2022-02-22</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/tensorflow/">tensorflow</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="第三章卷积介绍"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>注：该分类下的文章教程部分均来自MOOC的(<a target="_blank" rel="noopener" href="https://www.icourse163.org/course/youdao-1460578162">TensorFlow 入门实操课程_网易有道_中国大学MOOC(慕课) (icourse163.org)</a>),文章最后的练习部分是自己写的</p>
<h2 id="利用卷积提高计算机视觉精度">利用卷积提高计算机视觉精度</h2>
<p>在前几节课中，你看到了如何使用包含三层的深度神经网络（DNN）进行时Fashion MNIST图像识别–输入层（根据输入数据的形状）、输出层（根据类别数量）和一个隐藏层。你实验了不同大小的隐藏层、训练次数等对最终精度的影响。</p>
<p>为了方便起见，这里又提供了完整的代码。运行它，记下最后打印出来的测试精度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">mnist = tf.keras.datasets.fashion_mnist</span><br><span class="line">(training_images, training_labels), (test_images, test_labels) = mnist.load_data()</span><br><span class="line">training_images=training_images / <span class="number">255.0</span></span><br><span class="line">test_images=test_images / <span class="number">255.0</span></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">  tf.keras.layers.Flatten(),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">128</span>, activation=tf.nn.relu),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">10</span>, activation=tf.nn.softmax)</span><br><span class="line">])</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">model.fit(training_images, training_labels, epochs=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">test_loss = model.evaluate(test_images, test_labels)</span><br></pre></td></tr></table></figure>
<pre><code>Epoch 1/5
1875/1875 [==============================] - 2s 1ms/step - loss: 0.4969 - accuracy: 0.8265
Epoch 2/5
1875/1875 [==============================] - 2s 1ms/step - loss: 0.3727 - accuracy: 0.8669
Epoch 3/5
1875/1875 [==============================] - 2s 1ms/step - loss: 0.3372 - accuracy: 0.8781
Epoch 4/5
1875/1875 [==============================] - 2s 1ms/step - loss: 0.3131 - accuracy: 0.8859
Epoch 5/5
1875/1875 [==============================] - 2s 1ms/step - loss: 0.2955 - accuracy: 0.8921
313/313 [==============================] - 0s 897us/step - loss: 0.3591 - accuracy: 0.8744
</code></pre>
<p>你的训练准确率大概是89%，测试准确率大概是87%…还不错…但是如何让它变得更好呢？一种方法是使用一种叫做Convolutions的方法。这里不打算纠结于卷积的细节，而想抓住它的核心思路，即通过卷积操作缩小了图像的内容，将模型注意力集中在图像特定的、明显的特征上。</p>
<p>如果你曾经使用滤镜进行过图像处理（比如：<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Kernel_(image_processing)%EF%BC%89%EF%BC%8C%E9%82%A3%E4%B9%88convolutions%E7%9C%8B%E8%B5%B7%E6%9D%A5%E4%BC%9A%E9%9D%9E%E5%B8%B8%E7%86%9F%E6%82%89%E3%80%82">https://en.wikipedia.org/wiki/Kernel_(image_processing)），那么convolutions看起来会非常熟悉。</a></p>
<p>简而言之，如果取一个二维数组（通常是3x3或5x5）并将其应用到图像上。通过根据该矩阵内的公式改变底层像素，就可以进行图像边缘检测等工作。例如上面的链接，会看到一个3x3的矩阵，它是为边缘检测而定义的，其中间的单元格是8，而所有相邻单元格都是-1。在这种情况下，对于每个像素，把它的值乘以8，然后减去它周边像素的值（因为每个都乘了-1）。扫描整个图像，对每个像素都这样做，最终会得到一张边缘被增强的新图像。</p>
<p>这种计算对于计算机视觉来说是非常理想的，因为通常情况下，能够像这样被突出显示的特征才是区分一个物品和另一个物品的关键。卷积使得所需要的信息量会少很多…因为只需要对突出显示的特征进行训练。</p>
<p>这就是卷积神经网络的概念。在全连接层之前，增加一些层来做卷积，那么输入全连接层的信息就会更加集中，也可能更加准确。</p>
<p>运行下面的代码–这和前面的神经网络是一样的，但这次先加了卷积层。这会花费较长的时间，但看看对精度的影响。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="built_in">print</span>(tf.__version__)</span><br><span class="line">mnist = tf.keras.datasets.fashion_mnist</span><br><span class="line">(training_images, training_labels), (test_images, test_labels) = mnist.load_data()</span><br><span class="line">training_images=training_images.reshape(<span class="number">60000</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)</span><br><span class="line">training_images=training_images / <span class="number">255.0</span></span><br><span class="line">test_images = test_images.reshape(<span class="number">10000</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)</span><br><span class="line">test_images=test_images/<span class="number">255.0</span></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">  tf.keras.layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>,<span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)),</span><br><span class="line">  tf.keras.layers.MaxPooling2D(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">  tf.keras.layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>,<span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">  tf.keras.layers.MaxPooling2D(<span class="number">2</span>,<span class="number">2</span>),</span><br><span class="line">  tf.keras.layers.Flatten(),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">model.summary()</span><br><span class="line">model.fit(training_images, training_labels, epochs=<span class="number">5</span>)</span><br><span class="line">test_loss = model.evaluate(test_images, test_labels)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>2.2.0
Model: &quot;sequential_1&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 26, 26, 64)        640       
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 1600)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 128)               204928    
_________________________________________________________________
dense_3 (Dense)              (None, 10)                1290      
=================================================================
Total params: 243,786
Trainable params: 243,786
Non-trainable params: 0
_________________________________________________________________
Epoch 1/5
1875/1875 [==============================] - 35s 19ms/step - loss: 0.4311 - accuracy: 0.8443
Epoch 2/5
1875/1875 [==============================] - 35s 19ms/step - loss: 0.2897 - accuracy: 0.8949
Epoch 3/5
1875/1875 [==============================] - 35s 19ms/step - loss: 0.2473 - accuracy: 0.9079
Epoch 4/5
1875/1875 [==============================] - 35s 19ms/step - loss: 0.2162 - accuracy: 0.9205
Epoch 5/5
1875/1875 [==============================] - 35s 19ms/step - loss: 0.1914 - accuracy: 0.9292
313/313 [==============================] - 2s 5ms/step - loss: 0.2541 - accuracy: 0.9108
</code></pre>
<p>模型在训练数据上的精度可能上升到93%左右，在验证数据上可能上升到91%。</p>
<p>这是朝着正确方向取得的显著进步!</p>
<p>试着运行更多的epochs–比如20个epochs，然后观察结果! 虽然结果可能看起来非常好，但实际上验证结果可能会下降，这是因为&quot;过拟合&quot;造成的，后面将会讨论。</p>
<p>(简而言之，'过拟合’发生在网络模型从训练集中学习到的结果非常好，但它太狭隘了，只能识别训练数据，而在看到<em>其他</em>数据时效果不佳。举个例子，如果你一辈子只看到红色的鞋子，那么当你看到一双蓝色的麂皮鞋可能会感到迷惑…再举一例，应试教育往往使得学生只对做过的题目有很好的正确率，但对真实的问题却错误率很高）</p>
<p>接下来，观察程序代码，看看卷积模型是如何一步步建立的。</p>
<p>第一步是收集数据。你会注意到，这里和之前有一点变化，训练数据需要改变维度（shape）。这是因为第一次卷积期望一个包含所有数据的单一张量，所以要把训练数据设置为60000x28x28x1的一个4D列表，测试图像也是如此处理。如果不这样做，会在训练时得到一个错误，因为卷积操作将不能识别数据形状。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">mnist = tf.keras.datasets.fashion_mnist</span><br><span class="line">(training_images, training_labels), (test_images, test_labels) = mnist.load_data()</span><br><span class="line">training_images=training_images.reshape(60000, 28, 28, 1)</span><br><span class="line">training_images=training_images / 255.0</span><br><span class="line">test_images = test_images.reshape(10000, 28, 28, 1)</span><br><span class="line">test_images=test_images/255.0</span><br></pre></td></tr></table></figure>
<p>接下来是定义模型。首先要添加一个卷积层。参数是</p>
<ol>
<li>你想要生成的卷积数（过滤器数量）。这个数值是任意的，但最好是从32开始的倍数。</li>
<li>卷积的大小（过滤器的大小），在本例中为3x3网格。这是最常用的尺寸。</li>
<li>要使用的激活函数 – 在本例中，我们将使用relu，你可能还记得它相当于当x&gt;0时返回x，否则返回0。</li>
<li>在第一层，设定输入数据的形状。</li>
</ol>
<p>在卷积层之后加上一个MaxPooling层，用来压缩图像，同时保持卷积所强调的特征内容。通过为MaxPooling指定(2,2)，效果是将图像的大小缩小四分之一。它的想法是创建一个2x2的像素数组，然后选取最大的一个，从而将4个像素变成1个，在整个图像中重复这样做，这样做的结果是将水平像素的数量减半，垂直像素的数量减半，有效地将图像缩小25%。</p>
<p>可以调用model.summary()来查看网络的大小和形状，你会注意到，每一个MaxPooling（池化）层之后，图像的大小都会以这种方式减少为原来的1/4。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">  tf.keras.layers.Conv2D(32, (3,3), activation=&#x27;relu&#x27;, input_shape=(28, 28, 1)),</span><br><span class="line">  tf.keras.layers.MaxPooling2D(2, 2),</span><br></pre></td></tr></table></figure>
<p>再增加一个卷积层和MaxPooling2D</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.layers.Conv2D(64, (3,3), activation=&#x27;relu&#x27;),</span><br><span class="line">tf.keras.layers.MaxPooling2D(2,2)</span><br></pre></td></tr></table></figure>
<p>现在对输出进行扁平化处理。在这之后，你将拥有与非卷积版本相同的DNN结构，即全连接神经元网络。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.layers.Flatten(),</span><br></pre></td></tr></table></figure>
<p>含有128个神经元的全连接层，以及10个神经元的输出层。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">  tf.keras.layers.Dense(128, activation=&#x27;relu&#x27;),</span><br><span class="line">  tf.keras.layers.Dense(10, activation=&#x27;softmax&#x27;)</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<p>现在编译模型，调用model.fit方法做训练，接着用测试集评估损失和准确率。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model.compile(optimizer=&#x27;adam&#x27;, loss=&#x27;sparse_categorical_crossentropy&#x27;, metrics=[&#x27;accuracy&#x27;])</span><br><span class="line">model.fit(training_images, training_labels, epochs=5)</span><br><span class="line">test_loss, test_acc = model.evaluate(test_images, test_labels)</span><br><span class="line">print(test_acc)</span><br></pre></td></tr></table></figure>
<h2 id="将卷积和池化的结果可视化">将卷积和池化的结果可视化</h2>
<p>这段代码将以图形方式向我们展示卷积的结果。print(test_labels[;100])向我们展示了测试集中的前100个标签，你可以看到索引0、索引23和索引28的标签都是相同的值（9），它们都是鞋子。让我们来看看对图像做卷积操作的结果，会看到它们之间的共同特征出现。之后，当DNN在该数据上进行训练时，模型训练的工作内容就少了很多，模型会在卷积/池化的基础上找到鞋子图像的共性。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(test_labels[:<span class="number">100</span>])</span><br></pre></td></tr></table></figure>
<pre><code>[9 2 1 1 6 1 4 6 5 7 4 5 7 3 4 1 2 4 8 0 2 5 7 9 1 4 6 0 9 3 8 8 3 3 8 0 7
 5 7 9 6 1 3 7 6 7 2 1 2 2 4 4 5 8 2 2 8 4 8 0 7 7 8 5 1 1 2 3 9 8 7 0 2 6
 2 3 1 2 8 4 1 8 5 9 5 0 3 2 0 6 5 3 6 7 1 8 0 1 4 2]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">f, axarr = plt.subplots(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">FIRST_IMAGE=<span class="number">0</span></span><br><span class="line">SECOND_IMAGE=<span class="number">7</span></span><br><span class="line">THIRD_IMAGE=<span class="number">26</span></span><br><span class="line">CONVOLUTION_NUMBER = <span class="number">1</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> models</span><br><span class="line">layer_outputs = [layer.output <span class="keyword">for</span> layer <span class="keyword">in</span> model.layers]</span><br><span class="line">activation_model = tf.keras.models.Model(inputs = model.<span class="built_in">input</span>, outputs = layer_outputs)</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">4</span>):</span><br><span class="line">  f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>))[x]</span><br><span class="line">  axarr[<span class="number">0</span>,x].imshow(f1[<span class="number">0</span>, : , :, CONVOLUTION_NUMBER], cmap=<span class="string">&#x27;inferno&#x27;</span>)</span><br><span class="line">  axarr[<span class="number">0</span>,x].grid(<span class="literal">False</span>)</span><br><span class="line">  f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>))[x]</span><br><span class="line">  axarr[<span class="number">1</span>,x].imshow(f2[<span class="number">0</span>, : , :, CONVOLUTION_NUMBER], cmap=<span class="string">&#x27;inferno&#x27;</span>)</span><br><span class="line">  axarr[<span class="number">1</span>,x].grid(<span class="literal">False</span>)</span><br><span class="line">  f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>))[x]</span><br><span class="line">  axarr[<span class="number">2</span>,x].imshow(f3[<span class="number">0</span>, : , :, CONVOLUTION_NUMBER], cmap=<span class="string">&#x27;inferno&#x27;</span>)</span><br><span class="line">  axarr[<span class="number">2</span>,x].grid(<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p>​<br>
<img src="https://cdn.jsdelivr.net/gh/liwangshengya/picture/img/202202221726367.png" alt="png"><br>
​</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="built_in">print</span>(tf.__version__)</span><br><span class="line">mnist = tf.keras.datasets.fashion_mnist</span><br><span class="line">(training_images, training_labels), (test_images, test_labels) = mnist.load_data()</span><br><span class="line">training_images=training_images.reshape(<span class="number">60000</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)</span><br><span class="line">training_images=training_images / <span class="number">255.0</span></span><br><span class="line">test_images = test_images.reshape(<span class="number">10000</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)</span><br><span class="line">test_images=test_images/<span class="number">255.0</span></span><br><span class="line">network=keras.models.Sequential()</span><br><span class="line">network.add(keras.layers.Conv2D(<span class="number">64</span>,(<span class="number">2</span>,<span class="number">2</span>),activation=tf.nn.relu,input_shape=(<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)))</span><br><span class="line">network.add(keras.layers.MaxPooling2D(<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line">network.add(keras.layers.Conv2D(<span class="number">128</span>,(<span class="number">2</span>,<span class="number">2</span>),activation=tf.nn.relu))</span><br><span class="line">network.add(keras.layers.MaxPooling2D(<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">network.add(keras.layers.Flatten())</span><br><span class="line">network.add(keras.layers.Dense(<span class="number">200</span>,activation=tf.nn.relu))</span><br><span class="line">network.add(keras.layers.Dense(<span class="number">10</span>,activation=tf.nn.softmax))</span><br><span class="line">network.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">network.fit(training_images,training_labels,epochs=<span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<pre><code>2.7.0


2022-02-22 16:53:49.790908: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-02-22 16:53:50.300507: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 188160000 exceeds 10% of free system memory.


Epoch 1/5
1875/1875 [==============================] - 157s 83ms/step - loss: 0.4046 - accuracy: 0.8540
Epoch 2/5
1875/1875 [==============================] - 157s 84ms/step - loss: 0.2700 - accuracy: 0.8993
Epoch 3/5
1875/1875 [==============================] - 166s 89ms/step - loss: 0.2233 - accuracy: 0.9165
Epoch 4/5
1875/1875 [==============================] - 157s 84ms/step - loss: 0.1858 - accuracy: 0.9296
Epoch 5/5
1875/1875 [==============================] - 170s 91ms/step - loss: 0.1553 - accuracy: 0.9415





&lt;keras.callbacks.History at 0x7f4149a35fa0&gt;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">layer_outputs=[layer.output <span class="keyword">for</span> layer <span class="keyword">in</span> network.layers]</span><br><span class="line">activation_model=tf.keras.models.Model(inputs=network.<span class="built_in">input</span>,outputs=layer_outputs)</span><br><span class="line">pred=activation_model.predict(test_images[<span class="number">0</span>].reshape(<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">len</span>(pred)<span class="comment">#7层的输出</span></span><br></pre></td></tr></table></figure>
<pre><code>7
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.imshow(test_images[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.imshow(pred[<span class="number">1</span>][<span class="number">0</span>,:,:,<span class="number">1</span>])<span class="comment">#第一层卷积第二个过滤器</span></span><br></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f412e7f8610&gt;
</code></pre>
<p><img src="https://cdn.jsdelivr.net/gh/liwangshengya/picture/img/202202221726970.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">f,axarr=plt.subplots(<span class="number">4</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">4</span>):</span><br><span class="line">    axarr[i].imshow(pred[i][<span class="number">0</span>,:,:,<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.jsdelivr.net/gh/liwangshengya/picture/img/202202221726694.png" alt="png"></p>
<p>练习</p>
<ol>
<li>
<p>尝试修改卷积层参数。将32改为16或64。这对准确度和/或训练时间有什么影响？</p>
</li>
<li>
<p>删除最后的卷积层。这将对精度或训练时间产生什么影响？</p>
</li>
<li>
<p>增加更多的卷积层会有什么影响？实验一下吧。</p>
</li>
<li>
<p>除第一项外，删除所有的Convolutions。这样做会有什么影响？请完成实验。</p>
</li>
<li>
<p>在上一节课中，实现了通过一个回调函数来检查模型的损失，并在损失减小到一定量时取消训练。看看是否能在这里实现？</p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="built_in">print</span>(tf.__version__)</span><br><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">(training_images, training_labels), (test_images, test_labels) = mnist.load_data()</span><br><span class="line">training_images=training_images.reshape(<span class="number">60000</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)</span><br><span class="line">training_images=training_images / <span class="number">255.0</span></span><br><span class="line">test_images = test_images.reshape(<span class="number">10000</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)</span><br><span class="line">test_images=test_images/<span class="number">255.0</span></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">  tf.keras.layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>,<span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)),</span><br><span class="line">  tf.keras.layers.MaxPooling2D(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">  tf.keras.layers.Flatten(),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">model.fit(training_images, training_labels, epochs=<span class="number">10</span>)</span><br><span class="line">test_loss, test_acc = model.evaluate(test_images, test_labels)</span><br><span class="line"><span class="built_in">print</span>(test_acc)</span><br></pre></td></tr></table></figure>
<pre><code>2.2.0
Epoch 1/10
1875/1875 [==============================] - 17s 9ms/step - loss: 0.1538 - accuracy: 0.9537
Epoch 2/10
1875/1875 [==============================] - 17s 9ms/step - loss: 0.0519 - accuracy: 0.9843
Epoch 3/10
1875/1875 [==============================] - 16s 9ms/step - loss: 0.0345 - accuracy: 0.9890
Epoch 4/10
1875/1875 [==============================] - 17s 9ms/step - loss: 0.0226 - accuracy: 0.9934
Epoch 5/10
1875/1875 [==============================] - 17s 9ms/step - loss: 0.0154 - accuracy: 0.9955
Epoch 6/10
1875/1875 [==============================] - 17s 9ms/step - loss: 0.0105 - accuracy: 0.9965
Epoch 7/10
1875/1875 [==============================] - 17s 9ms/step - loss: 0.0086 - accuracy: 0.9972
Epoch 8/10
1875/1875 [==============================] - 16s 9ms/step - loss: 0.0065 - accuracy: 0.9978
Epoch 9/10
1875/1875 [==============================] - 17s 9ms/step - loss: 0.0057 - accuracy: 0.9981
Epoch 10/10
1875/1875 [==============================] - 17s 9ms/step - loss: 0.0039 - accuracy: 0.9987
313/313 [==============================] - 1s 3ms/step - loss: 0.0580 - accuracy: 0.9866
0.9865999817848206
</code></pre>
<h2 id="卷积的程序实现">卷积的程序实现</h2>
<p>这里，通过一张二维灰度图像，来探索卷积的工作原理。可以从scipy库中获取名为&quot;上升&quot;的图像。这是一张漂亮的内置图片，有很多角度和线条。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> misc</span><br><span class="line">i = misc.ascent()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>接下来，可以使用pyplot库来绘制图像，这样我们就能看到它的样子了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.grid(<span class="literal">False</span>)</span><br><span class="line">plt.gray()</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.imshow(i)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.jsdelivr.net/gh/liwangshengya/picture/img/202202221728554.png" alt="png"></p>
<p>图像是以numpy数组的形式存储的，所以我们只需复制这个数组就可以对图像进行转换。我们还可以得到图像的尺寸，这样就可以用循环遍历它的数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">i_transformed = np.copy(i)</span><br><span class="line">size_x = i_transformed.shape[<span class="number">0</span>]</span><br><span class="line">size_y = i_transformed.shape[<span class="number">1</span>]</span><br><span class="line">i_transformed.shape</span><br></pre></td></tr></table></figure>
<pre><code>(512, 512)
</code></pre>
<p>接下来创建一个3x3的过滤器</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This filter detects edges nicely</span></span><br><span class="line"><span class="comment"># It creates a convolution that only passes through sharp edges and straight</span></span><br><span class="line"><span class="comment"># lines.</span></span><br><span class="line"><span class="comment"># 这个过滤器可以很好地检测到边缘。</span></span><br><span class="line"><span class="comment"># 它通过卷积运算，只让尖锐的边缘和直线通过。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Experiment with different values for fun effects.</span></span><br><span class="line"><span class="comment">#试试看修改过滤器的数值，玩玩看</span></span><br><span class="line"><span class="comment">#filter = [ [0, 1, 0], [1, -4, 1], [0, 1, 0]]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># A couple more filters to try for fun!</span></span><br><span class="line"><span class="comment"># 另外的几个过滤器，纯粹为了好玩！</span></span><br><span class="line"><span class="built_in">filter</span> = [ [-<span class="number">1</span>, -<span class="number">2</span>, -<span class="number">1</span>], [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>]]</span><br><span class="line"><span class="comment">#filter = [ [-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># If all the digits in the filter don&#x27;t add up to 0 or 1, you </span></span><br><span class="line"><span class="comment"># should probably do a weight to get it to do so</span></span><br><span class="line"><span class="comment"># so, for example, if your weights are 1,1,1 1,2,1 1,1,1</span></span><br><span class="line"><span class="comment"># They add up to 10, so you would set a weight of .1 if you want to normalize them</span></span><br><span class="line"><span class="comment"># 如果过滤器中的所有数字加起来不是0或1，那么就应该设置权重，让过滤器的总和为0或1。</span></span><br><span class="line"><span class="comment"># 例如，如果过滤器是1，1，1，1，2，1，1，1，1。</span></span><br><span class="line"><span class="comment"># 它们加起来是10，所以可以设置0.1的权重，使它标准化。</span></span><br><span class="line">weight  = <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>接下来让我们创建一个卷积，扫描整个图像，留出1个像素的边框，并将当前像素的每个邻居乘以过滤器中定义的值。</p>
<p>即当前像素上方和左侧的邻域将乘以滤镜中左上方的项，等等。然后我们再将结果乘以权重，然后确保结果在0-255的范围内。</p>
<p>最后我们将把新的值加载到转换后的图像中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,size_x-<span class="number">1</span>):</span><br><span class="line">  <span class="keyword">for</span> y <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,size_y-<span class="number">1</span>):</span><br><span class="line">      convolution = <span class="number">0.0</span></span><br><span class="line">      convolution = convolution + (i[x - <span class="number">1</span>, y-<span class="number">1</span>] * <span class="built_in">filter</span>[<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line">      convolution = convolution + (i[x, y-<span class="number">1</span>] * <span class="built_in">filter</span>[<span class="number">0</span>][<span class="number">1</span>])</span><br><span class="line">      convolution = convolution + (i[x + <span class="number">1</span>, y-<span class="number">1</span>] * <span class="built_in">filter</span>[<span class="number">0</span>][<span class="number">2</span>])</span><br><span class="line">      convolution = convolution + (i[x-<span class="number">1</span>, y] * <span class="built_in">filter</span>[<span class="number">1</span>][<span class="number">0</span>])</span><br><span class="line">      convolution = convolution + (i[x, y] * <span class="built_in">filter</span>[<span class="number">1</span>][<span class="number">1</span>])</span><br><span class="line">      convolution = convolution + (i[x+<span class="number">1</span>, y] * <span class="built_in">filter</span>[<span class="number">1</span>][<span class="number">2</span>])</span><br><span class="line">      convolution = convolution + (i[x-<span class="number">1</span>, y+<span class="number">1</span>] * <span class="built_in">filter</span>[<span class="number">2</span>][<span class="number">0</span>])</span><br><span class="line">      convolution = convolution + (i[x, y+<span class="number">1</span>] * <span class="built_in">filter</span>[<span class="number">2</span>][<span class="number">1</span>])</span><br><span class="line">      convolution = convolution + (i[x+<span class="number">1</span>, y+<span class="number">1</span>] * <span class="built_in">filter</span>[<span class="number">2</span>][<span class="number">2</span>])</span><br><span class="line">      convolution = convolution * weight</span><br><span class="line">      <span class="keyword">if</span>(convolution&lt;<span class="number">0</span>):</span><br><span class="line">        convolution=<span class="number">0</span></span><br><span class="line">      <span class="keyword">if</span>(convolution&gt;<span class="number">255</span>):</span><br><span class="line">        convolution=<span class="number">255</span></span><br><span class="line">      i_transformed[x, y] = convolution</span><br></pre></td></tr></table></figure>
<p>现在，我们可以绘制图像，看看卷积的效果!</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Plot the image. Note the size of the axes -- they are 512 by 512</span></span><br><span class="line">plt.gray()</span><br><span class="line">plt.grid(<span class="literal">False</span>)</span><br><span class="line">plt.imshow(i_transformed)</span><br><span class="line"><span class="comment">#plt.axis(&#x27;off&#x27;)</span></span><br><span class="line">plt.show()   </span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.jsdelivr.net/gh/liwangshengya/picture/img/202202221729839.png" alt="png"></p>
<p>这段代码将显示一个（2，2）池化后的效果。它的想法是用2x2尺寸的矩阵在图像上扫描，查看像素和它的右方、下方和右下方的近邻像素。取其中最大的一个，并将其加载到新图像中。这样，新的图像将是旧图像的1/4大小–通过这个过程，X和Y上的尺寸减半。你会发现，尽管进行了这样的压缩，图像特征还是得到了保留。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">new_x = <span class="built_in">int</span>(size_x/<span class="number">2</span>)</span><br><span class="line">new_y = <span class="built_in">int</span>(size_y/<span class="number">2</span>)</span><br><span class="line">newImage = np.zeros((new_x, new_y))</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, size_x, <span class="number">2</span>):</span><br><span class="line">  <span class="keyword">for</span> y <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, size_y, <span class="number">2</span>):</span><br><span class="line">    pixels = []</span><br><span class="line">    pixels.append(i_transformed[x, y])</span><br><span class="line">    pixels.append(i_transformed[x+<span class="number">1</span>, y])</span><br><span class="line">    pixels.append(i_transformed[x, y+<span class="number">1</span>])</span><br><span class="line">    pixels.append(i_transformed[x+<span class="number">1</span>, y+<span class="number">1</span>])</span><br><span class="line">    newImage[<span class="built_in">int</span>(x/<span class="number">2</span>),<span class="built_in">int</span>(y/<span class="number">2</span>)] = <span class="built_in">max</span>(pixels)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot the image. Note the size of the axes -- now 256 pixels instead of 512</span></span><br><span class="line">plt.gray()</span><br><span class="line">plt.grid(<span class="literal">False</span>)</span><br><span class="line">plt.imshow(newImage)</span><br><span class="line"><span class="comment">#plt.axis(&#x27;off&#x27;)</span></span><br><span class="line">plt.show()      </span><br><span class="line">    </span><br><span class="line">    </span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.jsdelivr.net/gh/liwangshengya/picture/img/202202221729799.png" alt="png"></p>
<h2 id="练习">练习</h2>
<p>在视频中，你看了如何使用卷积来提高Fashion MNIST的识别率。通过这个练习，看看可否只使用单个卷积层和单个MaxPooling 2D将MNIST（手写数字）识别率提高到99.8%或更高的准确率。一旦准确率超过这个数值，应该停止训练。Epochs不应超过20个。如果epochs达到20但精度未达到要求，那么就需要重新设计层结构。</p>
<p>程序的框架已经有了–请完成它!</p>
<p>当达到99.8%的准确率时，你应该打印出 &quot;达到99.8%准确率，所以取消训练！&quot;的字符串。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># YOUR CODE STARTS HERE</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># YOUR CODE ENDS HERE</span></span><br><span class="line"></span><br><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">(training_images, training_labels), (test_images, test_labels) = mnist.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># YOUR CODE STARTS HERE</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># YOUR CODE ENDS HERE</span></span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    <span class="comment"># YOUR CODE STARTS HERE</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># YOUR CODE ENDS HERE</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># YOUR CODE STARTS HERE</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># YOUR CODE ENDS HERE</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">mycallbacks</span>(<span class="params">tf.keras.callbacks.Callback</span>):</span></span><br><span class="line"><span class="comment">#     def on_epoch_end(self,epoch,logs=&#123;&#125;):</span></span><br><span class="line"><span class="comment">#         if(log)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_epoch_end</span>(<span class="params">self, epoch, logs=&#123;&#125;</span>):</span></span><br><span class="line">        <span class="keyword">if</span>(logs.get(<span class="string">&#x27;accuracy&#x27;</span>)&gt;<span class="number">0.999</span>):</span><br><span class="line">          <span class="built_in">print</span>(<span class="string">&quot;\nReached 99.9% accuracy so cancelling training!&quot;</span>)</span><br><span class="line">          self.model.stop_training = <span class="literal">True</span></span><br><span class="line">callbacks=mycallbacks()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mnist=keras.datasets.mnist</span><br><span class="line">(training_images, training_labels), (test_images, test_labels) = mnist.load_data()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(training_images.shape)</span><br><span class="line"><span class="built_in">print</span>(training_labels.shape)</span><br></pre></td></tr></table></figure>
<pre><code>(60000, 28, 28)
(60000,)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">training_images=training_images.reshape(-<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)/<span class="number">255.0</span></span><br><span class="line">test_images=test_images.reshape(-<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)/<span class="number">255.0</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">network=keras.models.Sequential()</span><br><span class="line">network.add(keras.layers.Conv2D(<span class="number">64</span>,(<span class="number">2</span>,<span class="number">2</span>),activation=tf.nn.relu,input_shape=(<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)))</span><br><span class="line">network.add(keras.layers.MaxPooling2D(<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line"><span class="comment"># network.add(keras.layers.Conv2D(128,(2,2),activation=tf.nn.relu))</span></span><br><span class="line"><span class="comment"># network.add(keras.layers.MaxPooling2D(2,2))</span></span><br><span class="line"></span><br><span class="line">network.add(keras.layers.Flatten())</span><br><span class="line">network.add(keras.layers.Dense(<span class="number">200</span>,activation=tf.nn.relu))</span><br><span class="line">network.add(keras.layers.Dense(<span class="number">10</span>,activation=tf.nn.softmax))</span><br></pre></td></tr></table></figure>
<pre><code>2022-02-22 16:06:27.047181: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">network.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">network.fit(training_images,training_labels,epochs=<span class="number">20</span>,callbacks=callbacks)</span><br></pre></td></tr></table></figure>
<pre><code>2022-02-22 16:06:31.168558: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 188160000 exceeds 10% of free system memory.
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">Epoch <span class="number">1</span>/<span class="number">20</span></span><br><span class="line"><span class="number">1875</span>/<span class="number">1875</span> [==============================] - 150s 79ms/step - loss: <span class="number">0.1490</span> - accuracy: <span class="number">0.9558</span></span><br><span class="line">Epoch <span class="number">2</span>/<span class="number">20</span></span><br><span class="line"><span class="number">1875</span>/<span class="number">1875</span> [==============================] - 157s 84ms/step - loss: <span class="number">0.0534</span> - accuracy: <span class="number">0.9834</span></span><br><span class="line">Epoch <span class="number">3</span>/<span class="number">20</span></span><br><span class="line"><span class="number">1875</span>/<span class="number">1875</span> [==============================] - 149s 79ms/step - loss: <span class="number">0.0323</span> - accuracy: <span class="number">0.9898</span></span><br><span class="line">Epoch <span class="number">4</span>/<span class="number">20</span></span><br><span class="line"><span class="number">1875</span>/<span class="number">1875</span> [==============================] - 152s 81ms/step - loss: <span class="number">0.0212</span> - accuracy: <span class="number">0.9933</span></span><br><span class="line">Epoch <span class="number">5</span>/<span class="number">20</span></span><br><span class="line"><span class="number">1875</span>/<span class="number">1875</span> [==============================] - 150s 80ms/step - loss: <span class="number">0.0141</span> - accuracy: <span class="number">0.9955</span></span><br><span class="line">Epoch <span class="number">6</span>/<span class="number">20</span></span><br><span class="line"><span class="number">1875</span>/<span class="number">1875</span> [==============================] - 151s 81ms/step - loss: <span class="number">0.0097</span> - accuracy: <span class="number">0.9969</span></span><br><span class="line">Epoch <span class="number">7</span>/<span class="number">20</span></span><br><span class="line"><span class="number">1875</span>/<span class="number">1875</span> [==============================] - 150s 80ms/step - loss: <span class="number">0.0088</span> - accuracy: <span class="number">0.9972</span></span><br><span class="line">Epoch <span class="number">8</span>/<span class="number">20</span></span><br><span class="line"><span class="number">1875</span>/<span class="number">1875</span> [==============================] - 148s 79ms/step - loss: <span class="number">0.0072</span> - accuracy: <span class="number">0.9974</span></span><br><span class="line">Epoch <span class="number">9</span>/<span class="number">20</span></span><br><span class="line"><span class="number">1875</span>/<span class="number">1875</span> [==============================] - 149s 79ms/step - loss: <span class="number">0.0055</span> - accuracy: <span class="number">0.9982</span></span><br><span class="line">Epoch <span class="number">10</span>/<span class="number">20</span></span><br><span class="line"><span class="number">1875</span>/<span class="number">1875</span> [==============================] - 153s 82ms/step - loss: <span class="number">0.0046</span> - accuracy: <span class="number">0.9985</span></span><br><span class="line">Epoch <span class="number">11</span>/<span class="number">20</span></span><br><span class="line"><span class="number">1875</span>/<span class="number">1875</span> [==============================] - 147s 78ms/step - loss: <span class="number">0.0053</span> - accuracy: <span class="number">0.9983</span></span><br><span class="line">Epoch <span class="number">12</span>/<span class="number">20</span></span><br><span class="line"><span class="number">1875</span>/<span class="number">1875</span> [==============================] - 145s 77ms/step - loss: <span class="number">0.0032</span> - accuracy: <span class="number">0.9988</span></span><br><span class="line">Epoch <span class="number">13</span>/<span class="number">20</span></span><br><span class="line"><span class="number">1875</span>/<span class="number">1875</span> [==============================] - ETA: 0s - loss: <span class="number">0.0028</span> - accuracy: <span class="number">0.9991</span></span><br><span class="line">Reached <span class="number">99.9</span>% accuracy so cancelling training!</span><br><span class="line"><span class="number">1875</span>/<span class="number">1875</span> [==============================] - 147s 78ms/step - loss: <span class="number">0.0028</span> - accuracy: <span class="number">0.9991</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">network.evaluate(test_images,test_labels)</span><br></pre></td></tr></table></figure>
<pre><code>2022-02-22 16:48:20.830716: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 31360000 exceeds 10% of free system memory.


313/313 [==============================] - 6s 18ms/step - loss: 0.0745 - accuracy: 0.9861

[0.07454605400562286, 0.9861000180244446]
</code></pre>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/tensorflow/">tensorflow</a></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2022/02/19/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><img class="next-cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">循环神经网络</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/02/11/03%20%E7%AC%AC%E4%BA%8C%E7%AB%A0%20%E6%95%99%E7%A8%8B-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%AE%9E%E4%BE%8B%20/" title="第二章计算机视觉"><img class="cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-02-11</div><div class="title">第二章计算机视觉</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">忘生啊</div><div class="author-info__description"></div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">23</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">39</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/liwangshengya"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/liwangshengya" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:yxliwangsheng@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://t.me/wangshengya" target="_blank" title="telegram"><i class="fab fa-telegram"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%A9%E7%94%A8%E5%8D%B7%E7%A7%AF%E6%8F%90%E9%AB%98%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%B2%BE%E5%BA%A6"><span class="toc-number">1.</span> <span class="toc-text">利用卷积提高计算机视觉精度</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%86%E5%8D%B7%E7%A7%AF%E5%92%8C%E6%B1%A0%E5%8C%96%E7%9A%84%E7%BB%93%E6%9E%9C%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="toc-number">2.</span> <span class="toc-text">将卷积和池化的结果可视化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E7%9A%84%E7%A8%8B%E5%BA%8F%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.</span> <span class="toc-text">卷积的程序实现</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%83%E4%B9%A0"><span class="toc-number">4.</span> <span class="toc-text">练习</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/02/22/%E7%AC%AC%E4%B8%89%E7%AB%A0%E5%8D%B7%E7%A7%AF%E4%BB%8B%E7%BB%8D/" title="第三章卷积介绍"><img src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="第三章卷积介绍"/></a><div class="content"><a class="title" href="/2022/02/22/%E7%AC%AC%E4%B8%89%E7%AB%A0%E5%8D%B7%E7%A7%AF%E4%BB%8B%E7%BB%8D/" title="第三章卷积介绍">第三章卷积介绍</a><time datetime="2022-02-22T09:46:15.000Z" title="发表于 2022-02-22 17:46:15">2022-02-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/02/19/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="循环神经网络"><img src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="循环神经网络"/></a><div class="content"><a class="title" href="/2022/02/19/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="循环神经网络">循环神经网络</a><time datetime="2022-02-19T13:31:33.000Z" title="发表于 2022-02-19 21:31:33">2022-02-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/02/15/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="卷积神经网络"><img src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="卷积神经网络"/></a><div class="content"><a class="title" href="/2022/02/15/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="卷积神经网络">卷积神经网络</a><time datetime="2022-02-15T09:51:04.000Z" title="发表于 2022-02-15 17:51:04">2022-02-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/02/13/Linux%E5%BC%80%E5%90%AFswap/" title="Linux开启swap"><img src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Linux开启swap"/></a><div class="content"><a class="title" href="/2022/02/13/Linux%E5%BC%80%E5%90%AFswap/" title="Linux开启swap">Linux开启swap</a><time datetime="2022-02-13T11:28:02.000Z" title="发表于 2022-02-13 19:28:02">2022-02-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/02/11/03%20%E7%AC%AC%E4%BA%8C%E7%AB%A0%20%E6%95%99%E7%A8%8B-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%AE%9E%E4%BE%8B%20/" title="第二章计算机视觉"><img src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="第二章计算机视觉"/></a><div class="content"><a class="title" href="/2022/02/11/03%20%E7%AC%AC%E4%BA%8C%E7%AB%A0%20%E6%95%99%E7%A8%8B-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%AE%9E%E4%BE%8B%20/" title="第二章计算机视觉">第二章计算机视觉</a><time datetime="2022-02-11T14:15:15.000Z" title="发表于 2022-02-11 22:15:15">2022-02-11</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2021 - 2022 By 忘生啊</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Welcome😍</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">本地搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js"></script><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  typeof preloader === 'object' && preloader.initLoading()
  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>